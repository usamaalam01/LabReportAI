# Lab Report AI Interpretation API â€“ Comprehensive Specification (v2.1)

---

## 1. Intent

The **Lab Report AI Interpretation API** is a full-stack system designed to:
- Interpret clinical lab reports (blood, urine, stool, and standard clinical tests) for **educational insights**, **not diagnosis**.
- Provide structured outputs in Markdown and PDF with visual indicators (Red/Yellow/Green) and bar + gauge charts for abnormal or critical values.
- Support multi-language output (English + Urdu for v1) while **preserving medical terms** in parenthetical English.
- Ensure privacy via **PII sanitization** (all personal info scrubbed) and temporary storage (24â€“48 hours).
- Support **Website** uploads (Next.js) and **WhatsApp** chat interface (Twilio).
- Provide reference range sourcing (extracted from report; fallback to LLM medical knowledge with explicit note).

**Non-Goals / Out-of-Scope:**
- No medical diagnosis or treatment recommendation.
- No mobile app (v1).
- No multi-language input reports (English only).
- No EHR/EMR integration.
- No permanent data storage beyond retention period.
- No user accounts or authentication (v1) â€” reCAPTCHA only.
- No CI/CD pipeline (deferred to later stages).
- No advanced analytics beyond WhatsApp trends.

---

## 2. Architecture & Tech Stack

### Architecture Overview
- **Monorepo** structure: `/frontend` (Next.js) and `/backend` (FastAPI) in a single repository.
- **Async processing** via Celery workers â€” upload returns a `job_id`, frontend polls for status.
- **Docker Compose** orchestrates all services.

### Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| Frontend | Next.js (React) | Website UI |
| UI Components | Tailwind CSS + shadcn/ui | Styling and component library |
| Bot Protection | Google reCAPTCHA v3 | Invisible CAPTCHA on website |
| Backend API | FastAPI | REST API |
| Async Tasks | Celery + Redis | Background report processing |
| LLM Framework | LangChain | LLM orchestration (prompts, chains, output parsing) |
| LLM Analysis | GPT-4o (configurable) | Main report interpretation |
| LLM Validation | GPT-4o-mini (configurable) | Pre-validation (is it a lab report?) |
| OCR | PaddleOCR | Text extraction from images/PDFs |
| PDF Generation | WeasyPrint | HTML-to-PDF conversion |
| Charts | Matplotlib | Bar charts + gauge charts |
| Database | MySQL (SQLAlchemy + Alembic) | Report records persistence |
| Cache/Broker | Redis | Celery broker + WhatsApp session state |
| WhatsApp | Twilio WhatsApp Business API | Chat interface |
| Deployment | Docker Compose | Container orchestration |
| File Storage | Docker Volume | Uploaded files + generated PDFs |
| Logging | Python standard logging | Application logging |
| Prompts | Separate `.txt` files in `/prompts` | LLM prompt templates |

---

## 3. Success Criteria

- **Functional:**
  - Reports analyzed and returned in Markdown + PDF with all 7 output sections.
  - Bar + gauge charts generated for abnormal/critical values.
  - Reference ranges clearly identified with source noted.
  - WhatsApp bot collects age/gender before processing report.
- **Performance:**
  - Response time: 5â€“15 seconds per report.
  - Handles concurrent uploads without failure.
  - Polling-based async â€” instant job acknowledgment.
- **Safety / Accuracy:**
  - Mandatory disclaimers on all outputs.
  - Color coding (green/yellow/red) reflects LLM severity + rule-based mapping.
  - Urdu translation preserves medical terms in parenthetical English.
- **Configurability:**
  - File limits, page limits, LLM models, OCR engine, retention period, rate limits, and validation thresholds adjustable via environment variables.

---

## 4. Inputs / Outputs / Interfaces

### Inputs

| Field | Type | Notes |
|-------|------|-------|
| `user_id` | string | Unique session identifier; tracks WhatsApp flow |
| `age` | integer | Patient age; mandatory for WhatsApp, optional for website |
| `gender` | string | Male / Female / Other; mandatory for WhatsApp, optional for website |
| `language` | string | ISO code: `en` or `ur` (v1); defaults to `en` |
| `file` | file (multipart) | Uploaded report (PDF/JPG/PNG) â€” website uses multipart upload |
| `file_type` | string | MIME type: `application/pdf`, `image/jpeg`, `image/png` |
| `captcha_token` | string | Google reCAPTCHA v3 token (website only) |

### Outputs

| Output | Type | Notes |
|--------|------|-------|
| Markdown | string | Full 7-section interpretation with color indicators |
| PDF | file | Includes bar + gauge charts, color-coded tables (WeasyPrint) |
| Charts | image | Bar charts + gauge charts via Matplotlib, embedded in PDF |
| Error | JSON | Standardized: `{ "status": "error", "code": int, "message": str }` |

### API Endpoints

| Method | Endpoint | Purpose |
|--------|----------|---------|
| POST | `/v1/analyze-report` | Submit report; returns `{ "job_id": "..." }` |
| GET | `/v1/status/{job_id}` | Poll status; returns status, markdown, pdf_url, error |
| GET | `/v1/download/{job_id}` | Download generated PDF |
| POST | `/v1/whatsapp/webhook` | Twilio WhatsApp incoming webhook |
| GET | `/v1/health` | Health check for all services |

### Interfaces
- **Website:** Next.js upload form (file, age, gender, language selector) with reCAPTCHA v3. Polling-based loading UX with spinner â€” "Your report is being processed." Results rendered as formatted markdown with PDF download button.
- **WhatsApp:** Twilio webhook. Bot sends brief text message ("Your report is ready") + PDF attachment. No raw markdown over WhatsApp.
- **Storage:** Docker volume for uploaded files and generated PDFs. Auto-deleted after 24â€“48 hours.

---

## 5. Workflow / Logic

### Website Flow
1. User enters age/gender (optional), selects language, uploads report file. reCAPTCHA v3 validates.
2. System validates file type, size (â‰¤20 MB), and page count (â‰¤30 pages).
3. Backend saves file, creates DB record, dispatches Celery task, returns `job_id`.
4. Frontend redirects to results page, polls `GET /v1/status/{job_id}` every 2â€“3 seconds with loading spinner.
5. **Celery task pipeline:**
   a. OCR extraction (PaddleOCR) â€” extract text from image/PDF.
   b. Pre-validation â€” cheap LLM (GPT-4o-mini) confirms extracted text is a lab report.
   c. PII scrubbing â€” remove all personal info from OCR text.
   d. LLM analysis â€” GPT-4o interprets scrubbed text (English), returns structured JSON.
   e. Translation â€” if language â‰  English, translate via LLM (medical terms preserved with English in parentheses).
   f. Chart generation â€” Matplotlib creates bar + gauge charts for abnormal/critical values.
   g. PDF generation â€” WeasyPrint renders HTML template with charts and color-coded tables.
6. Frontend detects completion, renders markdown interpretation, shows PDF download button.
7. Error handling: invalid file, unreadable scan, unsupported lab, LLM failure â€” all return user-friendly messages.

### WhatsApp Flow (Twilio)
1. Bot prompts sequentially: Age â†’ Gender â†’ Report upload.
2. Redis state machine per phone number: `AWAITING_AGE` â†’ `AWAITING_GENDER` â†’ `AWAITING_REPORT` â†’ `PROCESSING`.
3. System validates file, runs same Celery pipeline as website.
4. On completion, bot sends brief text message + PDF attachment via Twilio.
5. Incomplete sessions auto-expire after 30 minutes (Redis TTL).
6. Handle edge cases: invalid age/gender input (retry prompt), blurred images, unsupported labs.

### Edge Cases / Exceptions
- **Blurred / low-quality images:** Attempt OCR â†’ detect garbage text via heuristic â†’ reject with re-upload message.
- **Unsupported/excessively long reports:** Enforce file size and page limits.
- **Non-English input:** Reports must be English; translation applied only to output.
- **Non-lab documents:** Pre-validation rejects with "This does not appear to be a lab report."
- **LLM failure:** Retry once; on second failure, return error message.
- **Chart/PDF failure:** Still return markdown (graceful degradation); log warning.

---

## 6. Output Format

### Interpretation Sections (ordered)
1. **Patient Info** â€” Age, gender (if provided), report date
2. **Summary** â€” 2â€“3 sentence high-level overview of findings
3. **Category-wise Results** â€” Grouped by: CBC, Liver Panel, Kidney Panel, Thyroid, Lipid Profile, etc. Each test shows: name, value, unit, reference range, source, severity
4. **Abnormal Values Analysis** â€” Detailed explanation of out-of-range values
5. **Clinical Associations** â€” Educational associations (not diagnostic)
6. **Lifestyle Tips** â€” General wellness recommendations related to findings
7. **Disclaimer** â€” Mandatory on every output

### Color Coding (Hybrid)
LLM assigns severity categories per test value. System applies consistent color mapping:
- ðŸŸ¢ **Green (Normal)** â€” Within reference range
- ðŸŸ¡ **Yellow (Borderline)** â€” Slightly outside reference range
- ðŸ”´ **Red (Critical)** â€” Significantly abnormal

**Severity indicators in markdown:** Use emoji circles (ðŸŸ¢ ðŸŸ¡ ðŸ”´) for universal rendering in markdown, web, and terminals. Frontend renders backend-generated markdown via `react-markdown` (not custom React components from JSON).

### Charts
- **Bar charts** â€” Horizontal bars per test category. Each test value vs. reference range. Color-coded green/yellow/red. Only generated for numeric test values (string values like "Positive" are skipped).
- **Gauge charts** â€” Speedometer-style for both **critical and borderline** values. Shows where patient's value falls within the overall range. Only for numeric values.
- **Placement in PDF** â€” Charts placed inline after each category table (bar chart â†’ gauge charts for that category's abnormal values).

### PDF Layout
- **Header** on each page: "Lab Report AI - Analysis Report"
- **Footer** on each page: page number + brief disclaimer note
- Professional, clean layout with color-coded table rows

### Reference Ranges
- LLM extracts reference ranges from the lab report text.
- If not present on the report, LLM uses its medical knowledge and the output explicitly states: *"Reference values not available in the report; ranges based on standard medical knowledge."*

### Translation (v1)
- **Languages:** English + Urdu
- **Medical terms:** Translated to target language with English in parentheses.
  - Example: ÛÛŒÙ…ÙˆÚ¯Ù„ÙˆØ¨Ù† (Hemoglobin) Ú©ÛŒ Ø³Ø·Ø­ Ù†Ø§Ø±Ù…Ù„ ÛÛ’Û”
- **RTL support** in PDF output for Urdu.

### Mandatory Disclaimer
> "This report provides educational insights and clinical associations only. It is not a diagnosis or treatment recommendation. Please consult a qualified physician."

---

## 7. Configuration Options

All options configurable via environment variables (`.env` file).

| Option | Default | Purpose |
|--------|---------|---------|
| `MAX_FILE_SIZE` | 20 MB | Maximum upload file size |
| `MAX_PAGES` | 30 | Maximum page count per report |
| `RETENTION_PERIOD` | 48h | Temporary storage auto-deletion period |
| `VALIDATION_THRESHOLD` | 0.8 | Pre-validation LLM confidence threshold |
| `LLM_ANALYSIS_MODEL` | gpt-4o | Primary LLM model for report analysis |
| `LLM_VALIDATION_MODEL` | gpt-4o-mini | Cheap LLM for pre-validation |
| `LLM_API_KEY` | (required) | OpenAI API key |
| `OCR_ENGINE` | PaddleOCR | OCR engine; alternative: `aws_textract` |
| `RATE_LIMIT_PER_IP` | 10/hour | Maximum report submissions per IP per hour |
| `RECAPTCHA_SECRET_KEY` | (required) | Google reCAPTCHA v3 server-side secret |
| `RECAPTCHA_SITE_KEY` | (required) | Google reCAPTCHA v3 client-side key |
| `TWILIO_ACCOUNT_SID` | (required for WhatsApp) | Twilio account SID |
| `TWILIO_AUTH_TOKEN` | (required for WhatsApp) | Twilio auth token |
| `TWILIO_WHATSAPP_NUMBER` | (required for WhatsApp) | Twilio WhatsApp sender number |
| `MYSQL_URL` | mysql://localhost:3306/labreportai | MySQL connection string |
| `REDIS_URL` | redis://localhost:6379/0 | Redis connection string |

---

## 8. Safety, Security & Privacy

### PII Sanitization
All personal information scrubbed from OCR text **before** sending to the LLM:

| PII Type | Action |
|----------|--------|
| Patient Name | Replaced with `[REDACTED]` |
| Patient ID / MRN | Removed |
| Phone Number | Replaced with `[PHONE_REDACTED]` |
| Address | Removed |
| Date of Birth | Replaced with `[DOB_REDACTED]` (age passed separately) |
| Doctor Name | Replaced with `[DOCTOR_REDACTED]` |
| Hospital / Lab Name | Replaced with `[LAB_REDACTED]` |

### Security Measures
- **HTTPS** required for all communications.
- **Google reCAPTCHA v3** (invisible, score-based) on website uploads.
- **Per-IP rate limiting** â€” 10 requests/hour (configurable).
- **No user authentication** for v1 â€” anonymous usage.
- Temporary file storage with **24â€“48h auto-deletion** via Celery Beat.
- No permanent storage of uploaded lab reports or generated outputs.

---

## 9. Database Schema

### MySQL â€” `reports` Table (v1)

| Column | Type | Notes |
|--------|------|-------|
| `id` | VARCHAR(36) PK | UUID |
| `job_id` | VARCHAR(36) UNIQUE | Celery task ID |
| `status` | ENUM | `pending`, `processing`, `completed`, `failed` |
| `file_path` | VARCHAR(500) | Path to uploaded file in storage volume |
| `file_type` | VARCHAR(50) | MIME type |
| `age` | INTEGER | Nullable |
| `gender` | VARCHAR(10) | Nullable |
| `language` | VARCHAR(5) | Default `en` |
| `ocr_text` | LONGTEXT | Scrubbed OCR text; nullable |
| `result_json` | LONGTEXT | Structured LLM output as JSON; nullable |
| `result_markdown` | LONGTEXT | Rendered markdown; nullable |
| `result_pdf_path` | VARCHAR(500) | Path to generated PDF; nullable |
| `error_message` | TEXT | Error details if failed; nullable |
| `source` | ENUM | `web`, `whatsapp`; default `web` |
| `whatsapp_number` | VARCHAR(20) | Phone number for WhatsApp reports; nullable |
| `ip_address` | VARCHAR(45) | Client IP for rate limiting |
| `expires_at` | DATETIME | Auto-deletion timestamp |
| `created_at` | DATETIME | Server default NOW |
| `updated_at` | DATETIME | On update NOW |

**Note:** User management tables deferred to future versions.

### Redis Keys
- `celery` â€” Celery broker and result backend
- `whatsapp:{phone_number}` â€” JSON hash: `{ state, age, gender, job_id }`. TTL: 30 minutes.
- `rate_limit:{ip}` â€” Integer counter. TTL: 1 hour.

---

## 10. Acceptance Criteria / Test Scenarios

1. Upload PDF/JPG/PNG â†’ validated â†’ OCR â†’ LLM analysis â†’ Markdown + PDF returned
2. WhatsApp flow: sequential Age/Gender/Report capture via Twilio â†’ text + PDF delivered
3. WhatsApp sends brief text message + PDF attachment (no raw markdown)
4. Blurred/low-quality images â†’ rejected with re-upload message
5. Non-lab documents (receipt, letter) â†’ rejected with "not a lab report" message
6. Urdu translation preserves medical terms in parenthetical English
7. Bar + gauge charts accurately reflect abnormal/critical values in PDF
8. All configuration options applied correctly (file size, pages, LLM model, OCR engine)
9. Reference range sources displayed; fallback note shown when ranges not on report
10. Disclaimers present on all Markdown and PDF outputs
11. reCAPTCHA v3 blocks bot submissions on website
12. Per-IP rate limiting enforced â€” 11th request in 1 hour returns 429
13. PII fully scrubbed â€” no personal info reaches the LLM
14. Files auto-deleted after retention period (24â€“48h)
15. Polling endpoint returns correct status transitions: `pending` â†’ `processing` â†’ `completed`/`failed`
16. Docker Compose starts all services: FastAPI, Celery worker, Celery Beat, Redis, MySQL, Next.js

---

## 11. Project Structure

```
labreportai/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.prod.yml
â”œâ”€â”€ Caddyfile
â”œâ”€â”€ deploy.sh
â”œâ”€â”€ .env.example
â”œâ”€â”€ .env.production.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ spec.md
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ Dockerfile.prod
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ next.config.js
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ .env.local.example
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ layout.tsx
â”‚       â”‚   â”œâ”€â”€ page.tsx
â”‚       â”‚   â”œâ”€â”€ globals.css
â”‚       â”‚   â””â”€â”€ report/[jobId]/page.tsx
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ui/                  (shadcn/ui components)
â”‚       â”‚   â”œâ”€â”€ UploadForm.tsx
â”‚       â”‚   â”œâ”€â”€ ReportView.tsx
â”‚       â”‚   â”œâ”€â”€ StatusPoller.tsx
â”‚       â”‚   â””â”€â”€ DisclaimerBanner.tsx
â”‚       â”œâ”€â”€ lib/
â”‚       â”‚   â”œâ”€â”€ api.ts
â”‚       â”‚   â””â”€â”€ utils.ts
â”‚       â””â”€â”€ types/
â”‚           â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ alembic.ini
â”‚   â”œâ”€â”€ alembic/
â”‚   â”‚   â””â”€â”€ versions/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                  (FastAPI app factory)
â”‚   â”‚   â”œâ”€â”€ config.py                (Pydantic Settings)
â”‚   â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ reports.py       (POST /analyze-report, GET /status, GET /download)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ whatsapp.py      (Twilio webhook)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ health.py        (GET /health)
â”‚   â”‚   â”‚   â””â”€â”€ middleware.py        (rate limiting, CORS)
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ report.py            (SQLAlchemy model)
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â””â”€â”€ report.py            (Pydantic request/response schemas)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ ocr.py               (PaddleOCR wrapper)
â”‚   â”‚   â”‚   â”œâ”€â”€ pii_scrubber.py      (Regex-based PII removal)
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_validator.py     (Pre-validation with GPT-4o-mini)
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_analyzer.py      (Main analysis with GPT-4o)
â”‚   â”‚   â”‚   â”œâ”€â”€ translator.py        (English â†’ Urdu translation)
â”‚   â”‚   â”‚   â”œâ”€â”€ chart_generator.py   (Matplotlib bar + gauge charts)
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_generator.py     (WeasyPrint HTML â†’ PDF)
â”‚   â”‚   â”‚   â”œâ”€â”€ markdown_renderer.py (JSON â†’ formatted Markdown)
â”‚   â”‚   â”‚   â”œâ”€â”€ file_validator.py    (Type, size, page count validation)
â”‚   â”‚   â”‚   â”œâ”€â”€ file_cleanup.py      (Auto-deletion logic)
â”‚   â”‚   â”‚   â””â”€â”€ whatsapp_sender.py   (Twilio outbound messages)
â”‚   â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”‚   â”œâ”€â”€ celery_app.py        (Celery configuration)
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze.py           (Main pipeline task)
â”‚   â”‚   â”‚   â””â”€â”€ cleanup.py           (Periodic cleanup task)
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â””â”€â”€ session.py           (SQLAlchemy engine + session)
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ logging.py           (Logging configuration)
â”‚   â”‚       â””â”€â”€ recaptcha.py         (reCAPTCHA v3 verification)
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ pre_validation.txt
â”‚   â”‚   â”œâ”€â”€ analysis.txt
â”‚   â”‚   â””â”€â”€ translation.txt
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ conftest.py
â”‚       â”œâ”€â”€ fixtures/               (Sample lab reports for testing)
â”‚       â”œâ”€â”€ test_file_validator.py
â”‚       â”œâ”€â”€ test_pii_scrubber.py
â”‚       â”œâ”€â”€ test_ocr.py
â”‚       â”œâ”€â”€ test_llm_analyzer.py
â”‚       â”œâ”€â”€ test_chart_generator.py
â”‚       â”œâ”€â”€ test_pdf_generator.py
â”‚       â”œâ”€â”€ test_api_reports.py
â”‚       â”œâ”€â”€ test_whatsapp.py
â”‚       â””â”€â”€ e2e/
â”‚           â”œâ”€â”€ test_full_pipeline_web.py
â”‚           â””â”€â”€ test_full_pipeline_whatsapp.py
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ pdf/
â”‚       â”œâ”€â”€ report.html              (Jinja2 template for WeasyPrint)
â”‚       â””â”€â”€ styles.css
â”‚
â””â”€â”€ storage/                          (Docker volume mount)
    â”œâ”€â”€ uploads/
    â””â”€â”€ outputs/
```

---

## 12. Implementation Plan (7 Phases)

Development follows a **vertical slice** approach â€” each phase delivers a working increment. Minimal unit tests per phase; comprehensive E2E tests in the final phase.

### Phase 1: Foundation & Infrastructure

**Goal:** Establish the monorepo, Docker Compose infrastructure, database, Celery plumbing, and a minimal end-to-end loop with a stub task. Upload a file â†’ see a placeholder result.

**What to build:**
- Monorepo scaffold: `/frontend` (Next.js + Tailwind + shadcn/ui), `/backend` (FastAPI)
- `docker-compose.yml` with services: `backend`, `celery-worker`, `redis`, `mysql`, `frontend`
- `.env.example` with all configuration variables
- SQLAlchemy + Alembic setup; initial migration creates `reports` table
- Pydantic Settings (`config.py`) reading env vars
- `POST /v1/analyze-report` â€” saves file to storage volume, creates DB row (status=`pending`), dispatches Celery task, returns `{ "job_id": "..." }`
- `GET /v1/status/{job_id}` â€” queries DB, returns status + results
- Stub Celery task: sleeps 3 seconds, updates DB to `completed` with placeholder markdown
- File validation service: checks MIME type, file size, page count
- Next.js upload form (file input, age, gender, language selector)
- Polling component: redirects to `/report/{jobId}`, polls every 3 seconds, shows spinner
- Basic result display (raw text for now)

**Verify:** `docker-compose up --build` â†’ open `http://localhost:3000` â†’ upload a PDF â†’ see placeholder text after ~3 seconds. Invalid files rejected.

---

### Phase 2: OCR, PII Scrubbing & Pre-Validation

**Goal:** Replace the stub with real OCR extraction, PII scrubbing, and pre-validation. Upload a real lab report â†’ see scrubbed extracted text. Non-lab documents rejected.

**What to build:**
- `ocr.py` â€” PaddleOCR wrapper. Handles images (direct OCR) and PDFs (convert pages to images via `pdf2image`, then OCR). Garbage text detection heuristic.
- `pii_scrubber.py` â€” Regex-based scrubbing for all 7 PII categories (name, ID, phone, address, DOB, doctor, hospital).
- `llm_validator.py` â€” LangChain + GPT-4o-mini. Loads prompt from `prompts/pre_validation.txt`. Returns `(is_lab_report, confidence)`. Compares against `VALIDATION_THRESHOLD`.
- `prompts/pre_validation.txt` â€” Prompt instructing LLM to classify document as lab report or not.
- Update Celery task: OCR â†’ PII scrub â†’ pre-validate â†’ store scrubbed text in DB.
- Alembic migration: add `ocr_text` column.
- Update Dockerfile: add PaddleOCR system dependencies, `poppler-utils`.
- Tests: `test_file_validator.py`, `test_pii_scrubber.py`, `test_ocr.py`.

**Verify:** Upload real lab report â†’ see scrubbed text (placeholder for analysis). Upload receipt â†’ rejected. Upload blurred image â†’ rejected.

---

### Phase 3: LLM Analysis (Core Intelligence)

**Goal:** Full LLM interpretation. Upload a lab report â†’ see a complete, meaningful 7-section interpretation with color-coded indicators.

**What to build:**
- `llm_analyzer.py` â€” LangChain + GPT-4o. Sends scrubbed text + age/gender. Returns structured JSON matching the output schema below. Uses LangChain output parsers. Retry logic (up to 2 retries).
- `prompts/analysis.txt` â€” Main analysis prompt (most critical prompt in the system). Instructs LLM to produce structured JSON with all 7 sections, severity classification, reference range sourcing.
- **Structured JSON output schema:**
  ```json
  {
    "patient_info": { "age": null, "gender": null, "report_date": null },
    "summary": "...",
    "categories": [
      {
        "name": "Complete Blood Count (CBC)",
        "tests": [
          {
            "test_name": "Hemoglobin",
            "value": 12.5,
            "unit": "g/dL",
            "reference_range": "13.0 - 17.0",
            "reference_source": "report | standard_knowledge",
            "severity": "normal | borderline | critical",
            "interpretation": "..."
          }
          // Note: `value` supports both numeric (12.5) and string ("Positive", "Reactive", "1+")
          // for qualitative lab results.
        ]
      }
    ],
    "abnormal_analysis": "...",
    "clinical_associations": "...",
    "lifestyle_tips": "...",
    "disclaimer": "..."
  }
  ```
- `markdown_renderer.py` â€” Converts JSON to formatted markdown with emoji circle indicators (ðŸŸ¢/ðŸŸ¡/ðŸ”´), tables per category, and all 7 sections.
- Frontend: install `react-markdown` + `remark-gfm`, render backend-generated markdown in `ReportView.tsx`. No custom React components from JSON â€” markdown-only rendering approach.
- `value` field supports both numeric and string types for qualitative lab results (e.g., "Positive", "Reactive").
- Alembic migration: add `result_json` column if not already present.
- Tests: `test_llm_analyzer.py` (mock LLM API).

**Verify:** Upload a CBC report â†’ see full interpretation with color-coded tables, severity labels, reference ranges, clinical associations, lifestyle tips, disclaimer.

---

### Phase 4: Charts & PDF Generation

**Goal:** Generate bar + gauge charts and a polished PDF. Upload a report â†’ download a professional PDF with embedded charts.

**What to build:**
- `chart_generator.py` â€” Matplotlib:
  - `generate_bar_chart()` â€” Horizontal bar chart per test category. Value vs. reference range. Color-coded bars (green/yellow/red).
  - `generate_gauge_chart()` â€” Speedometer-style gauge for each critical/abnormal value. Green/yellow/red zones, needle pointer.
  - `generate_all_charts()` â€” Orchestrator. Saves PNGs to `/storage/outputs/{job_id}/charts/`.
- `pdf_generator.py` â€” WeasyPrint:
  - Loads Jinja2 template from `templates/pdf/report.html`.
  - Renders all 7 sections, color-coded table rows, embedded chart images.
  - Outputs PDF to `/storage/outputs/{job_id}/report.pdf`.
- `templates/pdf/report.html` â€” Full Jinja2 HTML template with professional layout.
- `templates/pdf/styles.css` â€” Print-optimized CSS: color badges, page margins, chart sizing, page breaks, disclaimer styling.
- `GET /v1/download/{job_id}` â€” Returns PDF via `FileResponse`.
- Frontend: "Download PDF Report" button in `ReportView.tsx`.
- Tests: `test_chart_generator.py`, `test_pdf_generator.py`.

**Verify:** Upload report with abnormal values â†’ download PDF â†’ verify: professional layout, color tables, bar charts per category, gauge charts for critical values, all 7 sections, disclaimer.

---

### Phase 5: Security, Rate Limiting & File Cleanup

**Goal:** Production-harden the website. reCAPTCHA blocks bots, rate limiting prevents abuse, old files auto-deleted.

**What to build:**
- `recaptcha.py` â€” Verifies reCAPTCHA v3 token via Google API. Returns `(success, score)`. Configurable score threshold.
- Frontend: integrate reCAPTCHA v3 script. Execute before form submit, include token in request.
- `middleware.py` â€” Redis-based per-IP rate limiter. Uses `INCR` + `EXPIRE` on `rate_limit:{ip}` key. Returns 429 with `Retry-After` header when exceeded.
- `file_cleanup.py` â€” Queries expired reports from DB, deletes files from storage, updates/removes DB records.
- `tasks/cleanup.py` â€” Celery task wrapping cleanup logic.
- Celery Beat schedule: run cleanup every hour.
- `docker-compose.yml` â€” Add `celery-beat` service.
- Alembic migration: add `expires_at` column.
- Global exception handlers in `main.py`: consistent error JSON for 422, 429, 500.
- Tests: `test_api_reports.py` (reCAPTCHA mock, rate limiting, cleanup).

**Decisions:**
- **reCAPTCHA enforcement**: Optional â€” auto-skipped when `RECAPTCHA_SECRET_KEY` is empty. Enforced only when keys are configured. Allows development without Google keys.
- **File cleanup behavior**: Hard delete â€” delete uploaded files, generated PDFs/charts, AND remove the database record entirely. No trace remains after expiry.
- **Rate limiting scope**: Upload endpoint only (`POST /v1/analyze-report`, 10/hour per IP). Status polling and PDF downloads remain unlimited.
- **Celery Beat deployment**: Separate `celery-beat` Docker container in docker-compose.yml (same image, different command). Avoids duplicate runs with multiple workers.

**Verify:** reCAPTCHA blocks invalid tokens (when keys configured). 11th request from same IP returns 429. Old records with expired files cleaned up by Celery Beat.

---

### Phase 6: Translation & WhatsApp Integration

**Goal:** Add Urdu translation and the full Twilio WhatsApp bot. Both interfaces fully functional.

**What to build:**
- `translator.py` â€” LangChain LLM call. Translates structured JSON from English to Urdu. Medical terms preserved with English in parentheses. Loads prompt from `prompts/translation.txt`.
- `prompts/translation.txt` â€” Translation prompt with strict rules for medical term preservation.
- RTL support in `templates/pdf/report.html` for Urdu output.
- Urdu fonts added to backend Docker image (`fonts-noto-extra` or bundled `.ttf`).
- Frontend: language selector triggers translation when set to Urdu.
- `v1/whatsapp.py` â€” Twilio webhook endpoint:
  - Receives messages, manages Redis state machine: `AWAITING_AGE` â†’ `AWAITING_GENDER` â†’ `AWAITING_REPORT` â†’ `PROCESSING`.
  - Validates inputs (age: 1-120, gender: Male/Female/Other).
  - Downloads media from Twilio URL, dispatches Celery task.
  - Returns TwiML XML responses.
- `whatsapp_sender.py` â€” Twilio outbound: send text message + PDF media via Twilio API.
- Update Celery task: after completion for WhatsApp reports, call sender to deliver text + PDF.
- Alembic migration: add `source` (web/whatsapp) and `whatsapp_number` columns.
- Redis keys: `whatsapp:{phone_number}` with 30-minute TTL.
- Tests: `test_whatsapp.py`.

**Decisions:**
- **Twilio/WhatsApp**: Optional â€” endpoint registered but returns 503 when Twilio keys are empty/placeholder. No crash in dev mode.
- **Translation LLM**: Use validation model (8B) by default, but configurable via `LLM_TRANSLATION_MODEL` env var. Add `get_translation_llm()` factory.
- **Pipeline flow**: Translate JSON â†’ render Urdu markdown â†’ generate Urdu PDF. Charts stay numeric (language-neutral). One coherent Urdu output.
- **Urdu fonts**: Install `fonts-noto-extra` Debian package in Dockerfile.

**Verify:** Website with Urdu translation â€” medical terms in parentheses. WhatsApp: send age â†’ gender â†’ photo â†’ receive text + PDF.

---

### Phase 7: E2E Testing, Polish & Production Readiness

**Goal:** Comprehensive testing, error hardening, frontend polish, production Docker config. System ready for deployment.

**What to build:**
- `tests/e2e/test_full_pipeline_web.py` â€” 10+ test scenarios: valid reports, multi-panel, blurred, receipt, oversized, Urdu, rate limit, reCAPTCHA, concurrent uploads.
- `tests/e2e/test_full_pipeline_whatsapp.py` â€” Full flow, invalid inputs, session timeout, message during processing.
- `tests/fixtures/` â€” Sample lab report files for testing.
- Error handling hardening: specific error messages per failure type in Celery task. Graceful degradation (PDF fails â†’ still return markdown).
- Logging audit: ensure no PII or sensitive data in logs.
- Frontend polish:
  - File drag-and-drop zone.
  - Client-side file validation (type, size).
  - Progress steps during processing ("Extracting text...", "Analyzing report...", "Generating PDF...").
  - Responsive design (desktop + mobile).
  - Accessible: ARIA attributes, keyboard navigation.
  - "Upload Another Report" button.
- `v1/health.py` â€” Health check verifying MySQL, Redis, Celery connectivity.
- `docker-compose.prod.yml` â€” Production overrides: multi-stage Docker builds, `next build && next start`, uvicorn with 4 workers, health checks, restart policies, resource limits.
- Frontend Dockerfile: multi-stage build (build â†’ standalone production).
- Backend Dockerfile: non-root user, smaller image.
- `README.md` â€” Setup instructions, architecture, environment variables, API docs, troubleshooting.

**Verify:**
- `docker-compose -f docker-compose.yml -f docker-compose.prod.yml up --build` â€” all services start.
- `pytest tests/` â€” all unit + E2E tests pass.
- Manual: full website flow on desktop + mobile.
- Manual: full WhatsApp flow.
- `GET /v1/health` returns all services healthy.
- Docker logs: structured, no sensitive data.

**Phase 7 Implementation Decisions:**

**Decision 1 â€” Test Data & Fixtures:**
- Use existing sample files in `samples/` folder (no additional fixtures needed)
- Valid lab reports for positive testing:
  - `samples/Culture-Urine.pdf`
  - `samples/HIGH SENSITIVE TROPONIN -I.pdf`
  - `samples/Urine DR.pdf`
- Non-lab documents for rejection testing:
  - `samples/Lab Receipt.pdf`
  - `samples/Lab Receipt2.pdf`
- Total: 3 valid reports + 2 rejection test cases

**Decision 2 â€” LLM Testing Strategy:**
- Use real LLM calls for E2E tests (Option A)
- Tests will verify actual integration with LLM providers
- Requires valid API keys in test environment
- Expected test duration: ~5-10s per test
- Catches real API issues, response format changes, and integration problems

**Decision 3 â€” WhatsApp E2E Testing:**
- Use mocked Twilio webhook requests (Option A)
- Simulate Twilio POST requests with test payloads
- Mock Twilio media download API
- No actual WhatsApp messages sent during automated tests
- Real Twilio integration testing deferred to manual testing

**Decision 4 â€” Test Scenario Priorities:**
- Implement only must-have scenarios (Option A) - 5 core tests
- Test coverage:
  1. Valid lab report â†’ successful analysis (English)
  2. Valid lab report â†’ successful analysis (Urdu)
  3. Non-lab document (receipt) â†’ rejected with clear error
  4. Oversized file â†’ rejected
  5. Invalid file type â†’ rejected
- Additional scenarios (multi-panel, blurred, rate limiting, concurrent uploads) deferred

**Decision 5 â€” Frontend Polish Features:**
- Implement all features (Option D) - complete polish
- Features to implement:
  1. File drag-and-drop zone with visual feedback
  2. Client-side file validation (type: PDF/PNG/JPEG, size: max 10MB)
  3. Real-time progress indicators with polling (steps: "Extracting text...", "Analyzing report...", "Generating PDF...")
  4. Responsive design with mobile-friendly layout (media queries, touch targets)
  5. Accessibility: ARIA attributes, keyboard navigation, screen reader support
  6. "Upload Another Report" button on results page

**Decision 6 â€” Health Check Endpoint Scope:**
- Implement dependency checks (Option B)
- Health checks to implement:
  1. MySQL connectivity check (simple SELECT 1 query)
  2. Redis connectivity check (PING command)
  3. Celery worker availability check (inspect active workers)
- Response format: `{"status": "healthy|unhealthy", "checks": {"mysql": "ok|error", "redis": "ok|error", "celery": "ok|error"}}`
- Fast response (~100-200ms)
- Skip LLM/Twilio API checks to avoid external dependencies

**Decision 7 â€” README Documentation Depth:**
- Quick Start documentation (Option A)
- Sections to include:
  1. Project overview and features
  2. Quick start (docker-compose up instructions)
  3. Basic usage (how to upload a report)
  4. Environment variables list with required/optional markers
  5. Brief troubleshooting (common Docker issues)
- Target length: 1-2 pages
- Focus on getting users up and running quickly

**Decision 8 â€” Logging Audit:**
- Comprehensive audit (Option B)
- Audit tasks:
  1. Review all logging statements across backend codebase
  2. Create PII detection patterns (phone numbers, emails, patient names, test values)
  3. Implement log sanitization utility function
  4. Update all logs to sanitize sensitive data
  5. Test with real sample reports to verify no PII leaks
- PII to scrub: patient names, phone numbers, email addresses, test result values, addresses
- Keep safe: job_id, file types, error types, processing steps, timing metrics

**Decision 9 â€” Error Handling Hardening:**
- Specific error messages (Option B)
- Error categories to implement:
  1. OCR errors: "Text extraction failed - image quality too low", "Text extraction failed - unsupported format"
  2. Pre-validation errors: "Document rejected - not a lab report", "Document rejected - insufficient medical data"
  3. LLM errors: "Analysis failed - LLM timeout", "Analysis failed - invalid response format", "Analysis failed - rate limit exceeded"
  4. PDF errors: "PDF generation failed - chart rendering error", "PDF generation failed - template error"
  5. Translation errors: Already handled - falls back to English
- User-facing messages: Clear, actionable guidance
- Backend logs: Detailed error codes + stack traces for debugging
- No graceful degradation (except translation) - full processing or clear failure

---

## 13. Phase Dependency Chain

```
Phase 1: Foundation & Infrastructure
    â”‚
    â–¼
Phase 2: OCR, PII Scrubbing & Pre-Validation
    â”‚
    â–¼
Phase 3: LLM Analysis (Core Intelligence)
    â”‚
    â–¼
Phase 4: Charts & PDF Generation
    â”‚
    â–¼
Phase 5: Security, Rate Limiting & File Cleanup
    â”‚
    â–¼
Phase 6: Translation & WhatsApp Integration
    â”‚
    â–¼
Phase 7: E2E Testing, Polish & Production Readiness
```

Each phase builds on the previous. After Phase 1, you have a working stub loop. After Phase 4, the entire website pipeline works end-to-end with real analysis. Phases 5â€“6 add security and the secondary interface. Phase 7 hardens everything for production.

---

## 14. Future Considerations (Post-v1)

- User accounts and authentication (registration/login, report history)
- Additional languages beyond English + Urdu
- CI/CD pipeline (GitHub Actions: lint, test, build, deploy)
- AWS S3 file storage option (for production scalability)
- Mobile app
- EHR/EMR integration
- Advanced analytics dashboard
- Multi-language input report support

---

## 15. Production Deployment

### Production Architecture

```
Internet â†’ Caddy (HTTPS :443) â†’ Frontend (:3000)
                                â†’ Backend  (:8000)
         Internal only:
           MySQL (:3306), Redis (:6379), Celery Worker, Celery Beat
```

All 7 services run on a single VPS via Docker Compose. Caddy handles HTTPS termination and reverse proxying. Only ports 80 and 443 are exposed to the internet â€” all other services communicate internally via Docker networking.

### Hosting: Oracle Cloud Always-Free Tier

| Item | Details |
|------|---------|
| Provider | Oracle Cloud Infrastructure (OCI) |
| VM Shape | VM.Standard.A1.Flex (ARM Ampere) |
| Resources | 4 OCPUs, 24GB RAM, 200GB disk |
| Cost | $0/month (permanently free, not trial) |
| OS | Ubuntu 22.04 (ARM) |

Oracle Cloud's Always-Free Tier provides an ARM Ampere A1 instance with 4 CPUs and 24GB RAM â€” more than sufficient for all services. This is not a 12-month trial; the resources remain free indefinitely.

### Domain & SSL

| Item | Details |
|------|---------|
| Domain | DuckDNS free subdomain (e.g., `labreportai.duckdns.org`) |
| SSL | Automatic HTTPS via Caddy + Let's Encrypt |
| DNS Updates | Cron job updates DuckDNS IP every 5 minutes |

DuckDNS provides free dynamic DNS subdomains. A cron job keeps the DNS record updated with the server's current IP address. Caddy automatically provisions and renews SSL certificates from Let's Encrypt.

### Production Service Configuration

| Service | Image / Build | RAM Limit | Details |
|---------|--------------|-----------|---------|
| Caddy | `caddy:2-alpine` | 128 MB | Reverse proxy, auto-SSL, gzip compression |
| Frontend | `frontend/Dockerfile.prod` | 512 MB | Multi-stage build, Next.js standalone output (~150MB image) |
| Backend | `backend/Dockerfile` | 2 GB | 2 uvicorn workers, health checks every 30s |
| Celery Worker | Same as backend | 2 GB | 2 concurrency, restart always |
| Celery Beat | Same as backend | 256 MB | Periodic task scheduler |
| MySQL | `mysql:8.0` | 1 GB | Persistent volume, restart always |
| Redis | `redis:7-alpine` | 256 MB | Celery broker + session cache |

### Deployment Files

| File | Purpose |
|------|---------|
| `docker-compose.prod.yml` | Production overrides: resource limits, restart policies, Caddy service, no port exposure for internal services |
| `frontend/Dockerfile.prod` | Multi-stage Next.js build (`npm run build` â†’ standalone `node server.js`, ~150MB image) |
| `Caddyfile` | Reverse proxy routes: `/v1/*` â†’ backend, `/docs*` â†’ backend, everything else â†’ frontend. Auto-SSL. |
| `.env.production.example` | Production environment template with secure defaults and placeholder passwords |
| `deploy.sh` | One-command VPS setup: installs Docker, clones repo, configures environment, opens firewall, launches all services |

### Deployment Steps

1. **Create Oracle Cloud account** at cloud.oracle.com (free, credit card for identity verification only)
2. **Create ARM Compute Instance**: Shape `VM.Standard.A1.Flex`, 4 OCPU, 24GB RAM, Ubuntu 22.04, 100GB boot volume
3. **Open ports 80 and 443** in OCI Security List (VCN â†’ Subnet â†’ Security List â†’ Ingress Rules)
4. **Create DuckDNS subdomain** at duckdns.org (sign in with GitHub), point to instance public IP
5. **SSH into the instance** and run `deploy.sh`:
   ```bash
   # Clone and deploy
   git clone <repo-url> labreportai
   cd labreportai
   cp .env.production.example .env
   # Edit .env with real passwords and API keys
   nano .env
   # Launch all services
   bash deploy.sh
   ```
6. **Verify deployment**:
   - `https://labreportai.duckdns.org` â€” Frontend loads
   - `https://labreportai.duckdns.org/v1/health` â€” Returns `{"status": "healthy"}`
   - Upload a sample lab report â€” Full pipeline works
   - `docker compose logs -f` â€” No errors in logs

### Production Commands

```bash
# Start all services (production mode)
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build

# View logs (follow)
docker compose -f docker-compose.yml -f docker-compose.prod.yml logs -f

# View logs for a specific service
docker compose -f docker-compose.yml -f docker-compose.prod.yml logs -f backend

# Restart a service
docker compose -f docker-compose.yml -f docker-compose.prod.yml restart backend

# Stop all services
docker compose -f docker-compose.yml -f docker-compose.prod.yml down

# Update and redeploy
git pull
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build
```

### Security Checklist

- [ ] Strong unique MySQL password in `.env` (not defaults)
- [ ] LLM API key set in `.env` (not committed to git)
- [ ] Caddy provides HTTPS (auto-SSL via Let's Encrypt)
- [ ] Only ports 80 and 443 open to internet
- [ ] Backend, MySQL, Redis not directly accessible from internet
- [ ] Oracle Cloud firewall configured (Security List ingress rules)
- [ ] CORS origins set to production domain only

### Cost Summary

| Item | Cost |
|------|------|
| Oracle Cloud VM (ARM A1, 4 CPU / 24 GB) | $0/month (always free) |
| DuckDNS subdomain | $0 (free) |
| SSL certificate (Let's Encrypt via Caddy) | $0 (free) |
| Groq API (LLM â€” free tier: 30 req/min) | $0 (free) |
| **Total** | **$0/month** |
